{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9167358",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057da52",
   "metadata": {},
   "source": [
    "###  What are Recurrent Neural Networks, and how do they differ from traditional feedforward neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a732ad8",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNNs) handle sequential data by passing information through hidden states over time, unlike traditional feedforward networks where information flows in a single direction. This feedback loop allows RNNs to capture temporal dependencies and context from previous steps, making them ideal for tasks involving sequences, such as time-series prediction and language modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e493da",
   "metadata": {},
   "source": [
    "### Stacking RNN Layers and Bi-directional Architect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3ddf9",
   "metadata": {},
   "source": [
    "Stacking RNN layers allows models to learn more complex patterns by passing data through multiple layers of RNNs, which can enhance their ability to capture intricate temporal dependencies, though it may also increase computational complexity and risk of overfitting. Bi-directional RNNs process sequences in both forward and backward directions, enabling them to utilize context from both the past and future within the sequence, which often improves performance on tasks where understanding of the entire sequence is crucial. Together, these techniques can significantly enhance the model's capacity to handle complex sequential data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c582a49",
   "metadata": {},
   "source": [
    "###  What is a hybrid architecture in the context of sequence modeling? Provide examples of how combining RNNs with other deep learning models can enhance performance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f42f16",
   "metadata": {},
   "source": [
    "A hybrid architecture in sequence modeling combines RNNs with other models, like CNNs or attention mechanisms, to leverage their strengths. For instance, CNNs can extract features from sequences, which RNNs then use to capture temporal patterns, while attention mechanisms help focus on important parts of the sequence, enhancing tasks like translation and summarization. This combination improves performance by integrating the strengths of each model type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb49960",
   "metadata": {},
   "source": [
    "### List down types of RNN model and explain their structures and differences with RNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed88fa",
   "metadata": {},
   "source": [
    "Vanilla RNN: Basic RNN with a simple feedback loop where the output of the previous step influences the current step. It struggles with long-term dependencies due to vanishing gradient issues.\n",
    "\n",
    "LSTM (Long Short-Term Memory): Enhances vanilla RNNs with gating mechanisms (input, forget, and output gates) to better capture long-term dependencies and mitigate vanishing gradient problems.\n",
    "\n",
    "GRU (Gated Recurrent Unit): A variant of LSTM with fewer gates (reset and update gates), simplifying the architecture while still addressing long-term dependency issues effectively.\n",
    "\n",
    "Bidirectional RNN: Processes sequences in both forward and backward directions, capturing context from both past and future, unlike vanilla RNNs which only process in one direction.\n",
    "\n",
    "Stacked RNN: Consists of multiple RNN layers stacked on top of each other, allowing the model to learn more complex patterns and hierarchical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e76cc6",
   "metadata": {},
   "source": [
    "# Part 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3c414",
   "metadata": {},
   "source": [
    "### Implementing a Basic RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c54e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff0e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\archive (3)\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfab47e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kind of drawn in by the erotic scenes, only to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Some films just simply should not be remade. T...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This movie made it into one of my top 10 most ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I remember this film,it was the first film i h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>An awful film! It must have been up against so...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5   Probably my all-time favorite movie, a story o...  positive\n",
       "6   I sure would like to see a resurrection of a u...  positive\n",
       "7   This show was an amazing, fresh & innovative i...  negative\n",
       "8   Encouraged by the positive comments about this...  negative\n",
       "9   If you like original gut wrenching laughter yo...  positive\n",
       "10  Phil the Alien is one of those quirky films wh...  negative\n",
       "11  I saw this movie when I was about 12 when it c...  negative\n",
       "12  So im not a big fan of Boll's work but then ag...  negative\n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative\n",
       "14  This a fantastic movie of three prisoners who ...  positive\n",
       "15  Kind of drawn in by the erotic scenes, only to...  negative\n",
       "16  Some films just simply should not be remade. T...  positive\n",
       "17  This movie made it into one of my top 10 most ...  negative\n",
       "18  I remember this film,it was the first film i h...  positive\n",
       "19  An awful film! It must have been up against so...  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying some of the rows\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec15203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the features and labels from the dataset\n",
    "\n",
    "reviews = df['review'].values\n",
    "labels = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8714c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the sentiment to numeric value. 1 for a positive sentiment, 0 for a negative one\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee03cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing the first 5000 words in the dataset\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f9c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f182625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into training and testing \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5627e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#building the RNN model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e28b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38100914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 76ms/step - accuracy: 0.6158 - loss: 0.6324 - val_accuracy: 0.8069 - val_loss: 0.4317\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 77ms/step - accuracy: 0.7983 - loss: 0.4518 - val_accuracy: 0.7584 - val_loss: 0.4979\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.8341 - loss: 0.3796 - val_accuracy: 0.8033 - val_loss: 0.4485\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 98ms/step - accuracy: 0.9043 - loss: 0.2452 - val_accuracy: 0.7746 - val_loss: 0.5061\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 94ms/step - accuracy: 0.9270 - loss: 0.2031 - val_accuracy: 0.7935 - val_loss: 0.5414\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ece615ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7920 - loss: 0.5415\n",
      "Test Accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc981a",
   "metadata": {},
   "source": [
    "### Stacking RNN Layers and Bi-directional RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfaa5b",
   "metadata": {},
   "source": [
    "#### Stacking RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "411c2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "\n",
    "from tensorflow.keras.layers import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f8bdadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty model, which will later be full of the layers, after which the model will be compiled\n",
    "\n",
    "stacked_rnn_model = Sequential() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c6cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers to the model\n",
    "\n",
    "stacked_rnn_model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
    "stacked_rnn_model.add(SimpleRNN(64, return_sequences=True))\n",
    "stacked_rnn_model.add(SimpleRNN(64, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "792f9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stacked_rnn_model.add(Dropout(0.5))\n",
    "stacked_rnn_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f0059bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "\n",
    "stacked_rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9890cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 133ms/step - accuracy: 0.6335 - loss: 0.6268 - val_accuracy: 0.7336 - val_loss: 0.5364\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 134ms/step - accuracy: 0.7174 - loss: 0.5545 - val_accuracy: 0.8224 - val_loss: 0.4252\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.8196 - loss: 0.4176 - val_accuracy: 0.6553 - val_loss: 0.6257\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.7769 - loss: 0.4736 - val_accuracy: 0.8215 - val_loss: 0.4280\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 124ms/step - accuracy: 0.8688 - loss: 0.3104 - val_accuracy: 0.7545 - val_loss: 0.5373\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "stacked_rnn_history = stacked_rnn_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e068a1a",
   "metadata": {},
   "source": [
    "#### Bidirectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b99021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "708ded58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "bi_rnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f6c17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the layers\n",
    "\n",
    "bi_rnn_model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_length))\n",
    "bi_rnn_model.add(Bidirectional(SimpleRNN(64, return_sequences=False)))\n",
    "bi_rnn_model.add(Dropout(0.5))\n",
    "bi_rnn_model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91556bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "\n",
    "bi_rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "637a7294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 140ms/step - accuracy: 0.6049 - loss: 0.6474 - val_accuracy: 0.8265 - val_loss: 0.4033\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 134ms/step - accuracy: 0.8227 - loss: 0.4148 - val_accuracy: 0.8328 - val_loss: 0.3800\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.8618 - loss: 0.3330 - val_accuracy: 0.8464 - val_loss: 0.3718\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 128ms/step - accuracy: 0.8782 - loss: 0.3012 - val_accuracy: 0.8384 - val_loss: 0.4157\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 152ms/step - accuracy: 0.9051 - loss: 0.2435 - val_accuracy: 0.8372 - val_loss: 0.4038\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "bi_rnn_history = bi_rnn_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4f07612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.7920 - loss: 0.5415\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.7598 - loss: 0.5337\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.8321 - loss: 0.4061\n",
      "Basic RNN Test Accuracy: 0.7935\n",
      "Stacked RNN Test Accuracy: 0.7545\n",
      "Bi-Directional RNN Test Accuracy: 0.8372\n"
     ]
    }
   ],
   "source": [
    "#comparing the models\n",
    "\n",
    "basic_rnn_test_loss, basic_rnn_test_acc = model.evaluate(X_test, y_test)\n",
    "stacked_rnn_test_loss, stacked_rnn_test_acc = stacked_rnn_model.evaluate(X_test, y_test)\n",
    "bi_rnn_test_loss, bi_rnn_test_acc = bi_rnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Basic RNN Test Accuracy: {basic_rnn_test_acc:.4f}\")\n",
    "print(f\"Stacked RNN Test Accuracy: {stacked_rnn_test_acc:.4f}\")\n",
    "print(f\"Bi-Directional RNN Test Accuracy: {bi_rnn_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77507919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
